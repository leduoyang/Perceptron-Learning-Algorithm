# Perceptron Learning Algorithm

Implement a version of PLA by Matlab with visiting examples in fixed, pre-determined random cycles throughout the algorithm.

## Solution
1.Read from ‘hw1_8_train.dat’ ,Save samples into matrix ‘data’

2.Run the PLA experiment for 2000 times

3.Record the number of updates during each experiment

4.Calculate the mean of updates and Plot the histogram

### In each experiment…
```

set initial variables

and

Run the PLA and record the number of updates when update the w until the w divides the data perfectly, which means it will be 400 consecutive loops in which there are no mistakes occurred.

```

### After 2000 experiments
```

Calculate the mean of the number of updates in each experiment

and

Plot the histogram

```

## Variables
### Initial Variables
```

w - weight of PLA

t - the index of the sample now being considered

count - counter for consecutive successes

Idx - the order of visiting generated by random permutation

sample - put samples in matrix ‘data’ into this matrix with Idx order

numUpdates - record the number of updates during each experiment

```
### Variables in each Experiment
```

x0~x4 - 1, column 1~4 of the sample now being considered

y - column 5 of the sample now being considered

s - sign after executing Dot Product operation with w and x0~x4

```


